# -*- coding: utf-8 -*-
"""TG_BOT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jKR3kEtqjdkJUzVEVz3ww6b5qBOorSl7

### Importar
"""

!pip install python-telegram-bot ccxt pandas pandas_ta

!pip install "numpy<1.25"
!pip install nest_asyncio
!pip install requests

"""### Variables"""

import nest_asyncio
nest_asyncio.apply()

# --- Importaciones ---
import logging
import os
import pandas as pd
import pandas_ta as ta
import ccxt.async_support as ccxt # Usar async_support de ccxt
import requests # Para llamar a CoinGecko API
import time # Para posibles pausas por rate limit
import asyncio # Para pausas as√≠ncronas
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes, ApplicationBuilder # A√±adido ApplicationBuilder

# --- Configuraci√≥n ---
# !! NUNCA pongas tu token directamente en el c√≥digo en producci√≥n !!
# !! Usa variables de entorno o un archivo de configuraci√≥n seguro !!
# Para probar, puedes ponerlo aqu√≠ temporalmente, pero es mala pr√°ctica.
TELEGRAM_BOT_TOKEN = "7751073011:AAEeKadsCbaYAW3K0nBrKt4Mik0iIjLGY3Fa" # Reemplaza con tu token real

# /rsi Command Settings
NUM_COINS_TO_FETCH = 100 # How many coins to fetch from CoinGecko (max 250 per free page)
# !! KEEP LOW WHEN USING MULTIPLE TIMEFRAMES !!
NUM_COINS_TO_PROCESS = 100  # How many to actually process for /rsi (30 coins * 5 TFs = 150 API calls) - ADJUST CAREFULLY!
RSI_PERIOD = 14
RSI_OVERBOUGHT_THRESHOLD = 70
RSI_OVERSOLD_THRESHOLD = 30 # Threshold for oversold condition
TIMEFRAMES_TO_CHECK = ['5m', '15m', '1h', '4h', '1d'] # For /rsi command

# /analyze Command Settings
ANALYSIS_TIMEFRAMES = ['5m', '15m', '1h', '4h'] # For /analyze command
RSI_EXTREME_OVERBOUGHT = 75 # For the extra +10% analyze bonus
RSI_EXTREME_OVERSOLD = 15  # For the extra +10% analyze bonus
MA_CLOSE_TOLERANCE = 0.01 # Percentage (e.g., 0.01 = 1%) for "close to MA" check
MACD_SETTINGS = {'fast': 12, 'slow': 26, 'signal': 9} # Standard MACD periods
MA_PERIODS = {'fast': 50, 'slow': 200}

# General Settings
VS_CURRENCY = 'usd' # Base currency for CoinGecko market cap ranking
QUOTE_CURRENCY = 'USDT' # Quote currency for trading pairs (e.g., BTC/USDT)
CCXT_EXCHANGE_ID = 'gateio' # Exchange for OHLCV data (e.g., 'gateio', 'kucoin', 'mexc', 'binance')
API_CALL_PAUSE = 0.5 # Pause between ccxt fetch_ohlcv calls (seconds) - Increase if needed

# --- Logging Setup ---
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logging.getLogger("httpx").setLevel(logging.WARNING) # Reduce httpx verbosity
logging.getLogger("ccxt").setLevel(logging.WARNING) # Reduce ccxt verbosity
logger = logging.getLogger(__name__)

# --- Add the token list at the top with configurations ---
TOKENS_TO_ANALYZE = [
    "BTC/USDT", "ETH/USDT", "XRP/USDT", "BNB/USDT", "SOL/USDT", "DOGE/USDT", "ADA/USDT",
    "TRX/USDT", "FARTCOIN/USDT", "NPC/USDT", "LINK/USDT", "AVAX/USDT", "LEO/USDT", "XLM/USDT",
    "TON/USDT", "SHIB/USDT", "SUI/USDT", "VELO/USDT", "HBAR/USDT", "WOO/USDT", "BCH/USDT",
    "LTC/USDT", "HYPE/USDT", "DOT/USDT", "GT/USDT", "CRV/USDT", "INJ/USDT", "ROSE/USDT",
    "PI/USDT", "RUNE/USDT", "ZRO/USDT", "TAO/USDT", "DSYNC/USDT", "PEPE/USDT", "UNI/USDT",
    "APT/USDT", "GALA/USDT", "OKB/USDT", "GT/USDT", "ONDO/USDT", "NEAR/USDT", "TAO/USDT",
    "ID/USDT", "CPOOL/USDT", "AIXBT/USDT", "GRASS/USDT", "ICP/USDT", "CRO/USDT", "BOBA/USDT"
]

"""### Funciones auxiliares"""

# --- Initialize Exchange ---
# Initialize globally to be accessible by helper functions and post_shutdown cleanup
try:
    # Enable rate limiting in ccxt if needed (though manual pauses are also used)
    # exchange = getattr(ccxt, CCXT_EXCHANGE_ID)({'enableRateLimit': True})
    exchange = getattr(ccxt, CCXT_EXCHANGE_ID)()
    logger.info(f"Exchange {CCXT_EXCHANGE_ID} initialized.")
except AttributeError:
    logger.error(f"Error: Exchange ID '{CCXT_EXCHANGE_ID}' not found in ccxt.")
    exchange = None # Ensure exchange is None if init fails
except Exception as e:
    logger.error(f"Error initializing exchange {CCXT_EXCHANGE_ID}: {e}")
    exchange = None

# --- Helper Functions ---

async def get_top_coins_coingecko(num_coins: int, vs_currency: str) -> list:
    """Fetches the symbols of the top N coins by market cap from CoinGecko."""
    symbols = []
    max_per_page = 250
    pages_needed = (num_coins + max_per_page - 1) // max_per_page
    coins_fetched = 0
    logger.info(f"Fetching top {num_coins} coins from CoinGecko (vs {vs_currency})...")
    for page in range(1, pages_needed + 1):
        if coins_fetched >= num_coins: break
        url = f"https://api.coingecko.com/api/v3/coins/markets"
        params = {
            'vs_currency': vs_currency, 'order': 'market_cap_desc',
            'per_page': min(max_per_page, num_coins - coins_fetched),
            'page': page, 'sparkline': 'false', 'locale': 'en' }
        try:
            # Run synchronous requests call in a separate thread to avoid blocking asyncio loop
            response = await asyncio.to_thread(requests.get, url, params=params, timeout=15)
            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)
            data = response.json()
            page_symbols = [coin['symbol'].upper() for coin in data if 'symbol' in coin]
            symbols.extend(page_symbols)
            coins_fetched += len(page_symbols)
            logger.info(f"Fetched {len(page_symbols)} symbols from CoinGecko (page {page}). Total: {len(symbols)}")
            # Pause between pages if fetching multiple pages
            if pages_needed > 1: await asyncio.sleep(2)
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching data from CoinGecko API: {e}")
            return [] # Return empty list on failure
        except Exception as e:
             logger.error(f"Unexpected error processing CoinGecko data: {e}")
             return []
    logger.info(f"Total unique symbols fetched from CoinGecko: {len(set(symbols))}")
    return symbols[:num_coins] # Return only the number requested

async def find_rsi_extremes_multi_tf() -> tuple[dict, dict]:
    """
    üöÄ Scans for overbought/oversold coins across multiple timeframes.
    Returns: ({pair: [{'tf': tf, 'rsi': value}, ...]}, {same for oversold})
    """
    if not exchange:
        print("‚ùå Exchange not initialized!")
        return {}, {}

    results_overbought, results_oversold = {}, {}

    # Fetch top coins
    top_symbols = await get_top_coins_coingecko(NUM_COINS_TO_FETCH, VS_CURRENCY)
    if not top_symbols:
        print("‚ö†Ô∏è No coins fetched!")
        return {}, {}

    pairs = [f"{symbol}/{QUOTE_CURRENCY}" for symbol in top_symbols[:NUM_COINS_TO_PROCESS]]
    print(f"üîç Scanning {len(pairs)} pairs on TFs: {', '.join(TIMEFRAMES_TO_CHECK)}")

    for i, pair in enumerate(pairs, 1):
        for tf in TIMEFRAMES_TO_CHECK:
            try:
                ohlcv = await exchange.fetch_ohlcv(pair, timeframe=tf, limit=RSI_PERIOD + 150)
                await asyncio.sleep(API_CALL_PAUSE)

                if len(ohlcv) < RSI_PERIOD + 1:
                    continue

                df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                df.set_index('timestamp', inplace=True)

                df.ta.rsi(length=RSI_PERIOD, append=True)
                rsi = round(df[f'RSI_{RSI_PERIOD}'].dropna().iloc[-1], 2)

                if rsi > RSI_OVERBOUGHT_THRESHOLD:
                    print(f"üìà {pair} OVERBOUGHT on {tf}! RSI: {rsi}")
                    results_overbought.setdefault(pair, []).append({'tf': tf, 'rsi': rsi})
                elif rsi < RSI_OVERSOLD_THRESHOLD:
                    print(f"üìâ {pair} OVERSOLD on {tf}! RSI: {rsi}")
                    results_oversold.setdefault(pair, []).append({'tf': tf, 'rsi': rsi})

            except ccxt.RateLimitExceeded:
                print(f"‚è≥ Rate limit hit for {pair}@{tf}. Cooling off...")
                await asyncio.sleep(20)
            except (ccxt.NetworkError, ccxt.ExchangeError):
                continue
            except ccxt.BadSymbol:
                break
            except Exception as e:
                print(f"‚ö†Ô∏è Error on {pair}@{tf}: {e}")

        if i % 10 == 0:
            print(f"‚è±Ô∏è Progress: {i}/{len(pairs)} pairs scanned")

    print(f"üéâ Scan complete! Overbought: {len(results_overbought)} | Oversold: {len(results_oversold)}")
    return results_overbought, results_oversold

async def get_valid_trading_pairs(exchange, tokens: list) -> list:
    """Obtiene los pares de trading disponibles en el exchange y devuelve los tokens v√°lidos de la lista proporcionada."""
    valid_pairs = []
    try:
        await exchange.load_markets()
        available_pairs = exchange.symbols
        logger.info(f"Se cargaron {len(available_pairs)} pares de trading desde {CCXT_EXCHANGE_ID}.")

        for token in tokens:
            if token in available_pairs:
                valid_pairs.append(token)
            else:
                logger.warning(f"El token {token} no se encontr√≥ en los pares de trading de {CCXT_EXCHANGE_ID}.")

        logger.info(f"Se validaron {len(valid_pairs)}/{len(tokens)} tokens como disponibles en {CCXT_EXCHANGE_ID}.")
        return valid_pairs
    except Exception as e:
        logger.error(f"Error al obtener los pares de trading de {CCXT_EXCHANGE_ID}: {e}")
        return []

async def calculate_tf_scores(symbol: str, timeframe: str, exchange) -> tuple:
    """
    Calcula puntuaciones alcistas y bajistas para un s√≠mbolo en una temporalidad.
    Reglas: divergencias, MACD fuerza, MACD cruce, RSI, MA 50/200, tendencia, volumen, patrones de velas.
    Devuelve: (up_score, down_score, details)
    """
    up_score = 0
    down_score = 0
    details = []

    try:
        # Obtener datos OHLCV
        ohlcv = await exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=200)
        await asyncio.sleep(API_CALL_PAUSE)

        if not ohlcv or len(ohlcv) < 200:  # Necesitamos suficientes datos para MA 200
            return 0, 0, [f"No hay suficientes datos para {symbol} en {timeframe}"]

        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)

        # --- 1. Divergencias MACD ---
        macd_result = await detect_macd_divergences(symbol, timeframe, exchange)
        if macd_result['error']:
            details.append(f"{timeframe}: Error en MACD: {macd_result['error'][:50]}...")
        else:
            for div in macd_result['bullish']['classic']:
                up_score += 1
                details.append(f"{timeframe}: Divergencia MACD alcista cl√°sica (vela {div['candle_idx'] + 1} atr√°s)")
            for div in macd_result['bullish']['hidden']:
                up_score += 1
                details.append(f"{timeframe}: Divergencia MACD alcista oculta (vela {div['candle_idx'] + 1} atr√°s)")
            for div in macd_result['bearish']['classic']:
                down_score += 1
                details.append(f"{timeframe}: Divergencia MACD bajista cl√°sica (vela {div['candle_idx'] + 1} atr√°s)")
            for div in macd_result['bearish']['hidden']:
                down_score += 1
                details.append(f"{timeframe}: Divergencia MACD bajista oculta (vela {div['candle_idx'] + 1} atr√°s)")

        # --- 2. Divergencias RSI ---
        rsi_result = await detect_rsi_divergences(symbol, timeframe, exchange)
        if rsi_result['error']:
            details.append(f"{timeframe}: Error en RSI: {rsi_result['error'][:50]}...")
        else:
            for div in rsi_result['bullish']['classic']:
                up_score += 1
                details.append(f"{timeframe}: Divergencia RSI alcista cl√°sica (vela {div['candle_idx'] + 1} atr√°s)")
            for div in rsi_result['bullish']['hidden']:
                up_score += 1
                details.append(f"{timeframe}: Divergencia RSI alcista oculta (vela {div['candle_idx'] + 1} atr√°s)")
            for div in rsi_result['bearish']['classic']:
                down_score += 1
                details.append(f"{timeframe}: Divergencia RSI bajista cl√°sica (vela {div['candle_idx'] + 1} atr√°s)")
            for div in rsi_result['bearish']['hidden']:
                down_score += 1
                details.append(f"{timeframe}: Divergencia RSI bajista oculta (vela {div['candle_idx'] + 1} atr√°s)")

        # --- 3. MACD Fuerza ---
        df.ta.macd(fast=MACD_SETTINGS['fast'], slow=MACD_SETTINGS['slow'], signal=MACD_SETTINGS['signal'], append=True)
        hist_col = f'MACDh_{MACD_SETTINGS["fast"]}_{MACD_SETTINGS["slow"]}_{MACD_SETTINGS["signal"]}'
        if hist_col in df.columns and len(df) >= 2:
            if df[hist_col].iloc[-1] > df[hist_col].iloc[-2] and df[hist_col].iloc[-1] > 0:
                up_score += 1
                details.append(f"{timeframe}: MACD con fuerza alcista")
            elif df[hist_col].iloc[-1] < df[hist_col].iloc[-2] and df[hist_col].iloc[-1] < 0:
                down_score += 1
                details.append(f"{timeframe}: MACD con fuerza bajista")

        # --- 4. MACD Cruce de Cero ---
        if hist_col in df.columns and len(df) >= 2:
            if df[hist_col].iloc[-2] < 0 and df[hist_col].iloc[-1] >= 0:
                up_score += 1
                details.append(f"{timeframe}: MACD cruza cero (alcista)")
            elif df[hist_col].iloc[-2] > 0 and df[hist_col].iloc[-1] <= 0:
                down_score += 1
                details.append(f"{timeframe}: MACD cruza cero (bajista)")

        # --- 5. RSI Sobreventa/Sobrecompra ---
        df['rsi'] = df.ta.rsi(length=RSI_SETTINGS['length'])
        if 'rsi' in df.columns and not df['rsi'].dropna().empty:
            if df['rsi'].iloc[-1] < 30:
                up_score += 1
                details.append(f"{timeframe}: RSI sobrevendido (<30)")
            elif df['rsi'].iloc[-1] > 70:
                down_score += 1
                details.append(f"{timeframe}: RSI sobrecomprado (>70)")

        # --- 6. RSI Extremo ---
        if 'rsi' in df.columns and not df['rsi'].dropna().empty:
            if df['rsi'].iloc[-1] < 25:
                up_score += 1
                details.append(f"{timeframe}: RSI sobrevendido extremo (<25)")
            elif df['rsi'].iloc[-1] > 75:
                down_score += 1
                details.append(f"{timeframe}: RSI sobrecomprado extremo (>75)")

        # --- 7. Cerca de MA 50 ---
        df['sma_50'] = df['close'].rolling(window=50).mean()
        if 'sma_50' in df.columns and not df['sma_50'].dropna().empty:
            price = df['close'].iloc[-1]
            sma_50 = df['sma_50'].iloc[-1]
            if abs(price - sma_50) / sma_50 <= 0.02:  # Dentro del 2%
                if price > sma_50:
                    up_score += 1
                    details.append(f"{timeframe}: Precio cerca de SMA 50 (alcista)")
                else:
                    down_score += 1
                    details.append(f"{timeframe}: Precio cerca de SMA 50 (bajista)")

        # --- 8. Cerca de MA 200 ---
        df['sma_200'] = df['close'].rolling(window=200).mean()
        if 'sma_200' in df.columns and not df['sma_200'].dropna().empty:
            price = df['close'].iloc[-1]
            sma_200 = df['sma_200'].iloc[-1]
            if abs(price - sma_200) / sma_200 <= 0.02:  # Dentro del 2%
                if price > sma_200:
                    up_score += 2
                    details.append(f"{timeframe}: Precio cerca de SMA 200 (alcista)")
                else:
                    down_score += 2
                    details.append(f"{timeframe}: Precio cerca de SMA 200 (bajista)")

        # --- 9. A Favor de Tendencia ---
        if 'sma_50' in df.columns and not df['sma_50'].dropna().empty:
            price = df['close'].iloc[-1]
            sma_50 = df['sma_50'].iloc[-1]
            is_bullish_candle = df['close'].iloc[-1] > df['open'].iloc[-1]
            is_bearish_candle = df['close'].iloc[-1] < df['open'].iloc[-1]
            if price > sma_50 and is_bullish_candle:
                up_score += 1
                details.append(f"{timeframe}: A favor de tendencia alcista")
            elif price < sma_50 and is_bearish_candle:
                down_score += 1
                details.append(f"{timeframe}: A favor de tendencia bajista")

        # --- 10. Volumen Alto ---
        df['avg_volume'] = df['volume'].rolling(window=20).mean()
        if 'avg_volume' in df.columns and not df['avg_volume'].dropna().empty:
            if df['volume'].iloc[-1] > df['avg_volume'].iloc[-1] * 1.5:
                if df['close'].iloc[-1] > df['open'].iloc[-1]:
                    up_score += 1
                    details.append(f"{timeframe}: Volumen alto en vela alcista")
                else:
                    down_score += 1
                    details.append(f"{timeframe}: Volumen alto en vela bajista")

        # --- 11. Patrones de Velas (Vela Envolvente) ---
        if len(df) >= 2:
            last_candle = df.iloc[-1]
            prev_candle = df.iloc[-2]
            if (last_candle['close'] > last_candle['open'] and
                prev_candle['close'] < prev_candle['open'] and
                last_candle['close'] > prev_candle['open'] and
                last_candle['open'] < prev_candle['close']):
                up_score += 1
                details.append(f"{timeframe}: Vela envolvente alcista")
            elif (last_candle['close'] < last_candle['open'] and
                  prev_candle['close'] > prev_candle['open'] and
                  last_candle['close'] < prev_candle['open'] and
                  last_candle['open'] > prev_candle['close']):
                down_score += 1
                details.append(f"{timeframe}: Vela envolvente bajista")

        return up_score, down_score, details

    except Exception as e:
        logger.warning(f"Error calculando puntuaciones para {symbol} en {timeframe}: {e}")
        return 0, 0, [f"Error en {timeframe}: {str(e)[:50]}..."]

async def calculate_asset_bias(symbol: str, timeframes: list) -> dict:
    """
    (For /analyze command)
    Calculates aggregated UP/DOWN scores and timeframe biases for a single asset.
    Returns: {'total_up': score, 'total_down': score, 'tf_results': {tf: {'up':X,'down':Y,'error':Z}}, 'errors': []}
    """
    tf_results_dict = {}
    errors = []

    # Run calculations concurrently
    tasks = [calculate_tf_scores(symbol, tf) for tf in timeframes]
    results = await asyncio.gather(*tasks, return_exceptions=True) # Catch exceptions from tasks

    total_up = 0
    total_down = 0

    for result in results:
        if isinstance(result, Exception):
            # Handle exceptions raised during task execution (less likely with try/except inside task)
            logger.error(f"Exception during gather for {symbol}: {result}")
            errors.append(f"Task execution error: {result}")
            # Cannot determine timeframe easily here if task failed before returning dict
            continue
        elif isinstance(result, dict):
            tf = result['tf'] # Get timeframe from result dict
            tf_results_dict[tf] = result # Store the full result dict
            if result['error']:
                errors.append(f"{tf}: {result['error']}")
            else:
                total_up += result['up']
                total_down += result['down']
        else:
             logger.error(f"Unexpected result type in gather for {symbol}: {type(result)}")
             errors.append("Unknown task result type")


    return {'total_up': total_up, 'total_down': total_down, 'tf_results': tf_results_dict, 'errors': errors}

"""### Start"""

# --- Bot Command Handlers ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Sends a welcome message when the /start command is issued."""
    user = update.effective_user
    await update.message.reply_html(
        rf"Hi {user.mention_html()}! I'm your crypto RSI & Analysis bot."
    )
    await help_command(update, context) # Show help on start

"""### Help"""

# --- Actualizaci√≥n de /help ---
async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """üìú Env√≠a una gu√≠a r√°pida de los comandos disponibles."""
    help_text = [
        "‚ú® **Comandos del Bot** ‚ú®",
        "",
        "üöÄ **/start** - Inicia el bot con un mensaje de bienvenida.",
        "",
        "üìú **/help** - Muestra esta gu√≠a √∫til.",
        "",
        f"üìà **/rsi** - Escanea ~{NUM_COINS_TO_PROCESS} monedas principales en {CCXT_EXCHANGE_ID} para extremos de RSI " +
        f"(sobrecompra > {RSI_OVERBOUGHT_THRESHOLD}, sobreventa < {RSI_OVERSOLD_THRESHOLD}) en {', '.join(TIMEFRAMES_TO_CHECK)}. " +
        "‚è≥ *¬°Puede tomar unos minutos!*",
        "",
        f"üîç **/analyze [S√çMBOLO]** - Punt√∫a una moneda (por ejemplo, BTC/USDT) para sesgo alcista/bajista usando reglas de an√°lisis t√©cnico en " +
        f"{', '.join(ANALYSIS_TIMEFRAMES)}, con contexto BTC/ETH. " +
        "‚ö†Ô∏è *¬°Experimental, no es asesoramiento financiero!*",
        "",
        f"üìä **/bias** - Encuentra las 10 monedas m√°s probables de subir o bajar de una lista de {len(TOKENS_TO_ANALYZE)} tokens, " +
        f"basado en puntuaciones de an√°lisis t√©cnico en {', '.join(ANALYSIS_TIMEFRAMES)}. " +
        "‚è≥ *¬°Puede tomar unos minutos!*",
        "",
        f"üìâ **/macd_divergences** - Detecta divergencias del MACD (cl√°sicas y ocultas, alcistas y bajistas) en las √∫ltimas 6 velas " +
        f"de {len(TOKENS_TO_ANALYZE)} tokens en {', '.join(MACD_DIVERGENCE_TIMEFRAMES)}. " +
        "‚è≥ *¬°Puede tomar unos minutos!*",
        "",
        f"üìâ **/rsi_divergences** - Detecta divergencias del RSI (cl√°sicas y ocultas, alcistas y bajistas) en las √∫ltimas 6 velas " +
        f"de {len(TOKENS_TO_ANALYZE)} tokens en {', '.join(RSI_DIVERGENCE_TIMEFRAMES)}. " +
        "‚è≥ *¬°Puede tomar unos minutos!*"
    ]
    await update.message.reply_text("\n".join(help_text), parse_mode='Markdown')

"""### RSI"""

async def rsi_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """üéØ /rsi: Scans top coins for overbought/oversold RSI across timeframes."""
    await update.message.reply_text(
        f"üîç **RSI Scan Started!** Checking top ~{NUM_COINS_TO_PROCESS} coins on {', '.join(TIMEFRAMES_TO_CHECK)}.\n"
        f"üìä OB > {RSI_OVERBOUGHT_THRESHOLD} | OS < {RSI_OVERSOLD_THRESHOLD} (via {CCXT_EXCHANGE_ID})\n"
        f"‚è≥ *This may take a few minutes...*"
    )

    try:
        overbought, oversold = await find_rsi_extremes_multi_tf()

        if not overbought and not oversold:
            await update.message.reply_text(
                f"‚úÖ **No RSI extremes found!** Scanned top {NUM_COINS_TO_PROCESS} coins on {', '.join(TIMEFRAMES_TO_CHECK)}."
            )
            return

        # Build message
        parts = []
        if overbought:
            parts.append(f"üìà **Overbought (RSI > {RSI_OVERBOUGHT_THRESHOLD})**")
            for pair, data in sorted(overbought.items()):
                tf_rsi = [f"{item['tf']} ({item['rsi']})" for item in sorted(data, key=lambda x: TIMEFRAMES_TO_CHECK.index(x['tf']))]
                parts.append(f"‚Ä¢ ${pair}: {', '.join(tf_rsi)}")  # Added $ before pair
            parts.append("")

        if oversold:
            parts.append(f"üìâ **Oversold (RSI < {RSI_OVERSOLD_THRESHOLD})**")
            for pair, data in sorted(oversold.items()):
                tf_rsi = [f"{item['tf']} ({item['rsi']})" for item in sorted(data, key=lambda x: TIMEFRAMES_TO_CHECK.index(x['tf']))]
                parts.append(f"‚Ä¢ ${pair}: {', '.join(tf_rsi)}")  # Added $ before pair
            parts.append("")

        parts.append(f"‚ÑπÔ∏è *Scanned ~{NUM_COINS_TO_PROCESS} coins. Not financial advice.*")
        message = "\n".join(parts)

        # Handle long messages
        max_len = 4096
        if len(message) <= max_len:
            await update.message.reply_text(message, parse_mode='Markdown')
        else:
            print(f"‚ö†Ô∏è Message too long ({len(message)} chars). Splitting...")
            chunks, current = [], ""
            title = f"RSI Scan Results (Top {NUM_COINS_TO_PROCESS})"
            part_num = 1
            for line in message.split('\n'):
                if len(current) + len(line) + len(title) + 20 < max_len:
                    current += line + "\n"
                else:
                    chunks.append(current)
                    current = line + "\n"
                    part_num += 1
            chunks.append(current)

            for i, chunk in enumerate(chunks, 1):
                if chunk.strip():
                    await update.message.reply_text(f"**{title} (Part {i}/{len(chunks)})**\n\n{chunk}", parse_mode='Markdown')
                    await asyncio.sleep(0.6)

    except Exception as e:
        print(f"‚ùå Error in /rsi: {e}")
        await update.message.reply_text("üö® Oops! Something went wrong with the /rsi scan.")

"""### BIAS"""

async def bias_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """üéØ /bias: Finds top 10 coins likely to go UP or DOWN from the token list."""
    await update.message.reply_text(
        f"üîç **Bias Scan Started!** Analyzing {len(TOKENS_TO_ANALYZE)} tokens on {', '.join(ANALYSIS_TIMEFRAMES)}.\n"
        f"üìä Fetching UP/DOWN probabilities via {CCXT_EXCHANGE_ID}.\n"
        f"‚è≥ *This may take a few minutes...*"
    )

    try:
        # Dictionary to store results
        bias_results = []
        errors = []

        # Process each token
        for i, symbol in enumerate(TOKENS_TO_ANALYZE, 1):
            logger.info(f"Processing {symbol} ({i}/{len(TOKENS_TO_ANALYZE)})")
            result = await calculate_asset_bias(symbol, ANALYSIS_TIMEFRAMES)

            if result['tf_results']:
                bias_results.append({
                    'symbol': symbol,
                    'total_up': result['total_up'],
                    'total_down': result['total_down']
                })
            if result['errors']:
                errors.append(f"{symbol}: {result['errors'][0][:50]}...")

            # Log progress every 10 tokens
            if i % 10 == 0:
                await update.message.reply_text(
                    f"‚è±Ô∏è Progress: {i}/{len(TOKENS_TO_ANALYZE)} tokens scanned."
                )
            await asyncio.sleep(API_CALL_PAUSE)  # Respect rate limits

        # Sort results
        top_up = sorted(bias_results, key=lambda x: x['total_up'], reverse=True)[:10]
        top_down = sorted(bias_results, key=lambda x: x['total_down'], reverse=True)[:10]

        # Build response
        parts = [f"üìä **Bias Scan Results ({len(bias_results)}/{len(TOKENS_TO_ANALYZE)} tokens analyzed)**"]

        # Top 10 UP
        if top_up:
            parts.append("\nüìà **Top 10 Likely to Go UP**")
            for i, res in enumerate(top_up, 1):
                parts.append(f"{i}. ${res['symbol']}: ‚Üë{res['total_up']}% ‚Üì{res['total_down']}%")  # Added $ before symbol
        else:
            parts.append("\nüìà **Top 10 Likely to Go UP**: No results.")

        # Top 10 DOWN
        if top_down:
            parts.append("\nüìâ **Top 10 Likely to Go DOWN**")
            for i, res in enumerate(top_down, 1):
                parts.append(f"{i}. ${res['symbol']}: ‚Üë{res['total_up']}% ‚Üì{res['total_down']}%")  # Added $ before symbol
        else:
            parts.append("\nüìâ **Top 10 Likely to Go DOWN**: No results.")

        # Errors
        if errors:
            parts.append("\n‚ö†Ô∏è **Issues**")
            parts.extend([f"‚Ä¢ {err}" for err in errors[:5]])  # Limit to 5 errors for brevity
            if len(errors) > 5:
                parts.append(f"‚Ä¢ ...and {len(errors) - 5} more.")

        parts.append("\n‚ÑπÔ∏è *Not financial advice! Scores are for insight only. DYOR!*")
        message = "\n".join(parts)

        # Handle long messages
        max_len = 4096
        if len(message) <= max_len:
            await update.message.reply_text(message, parse_mode='Markdown')
        else:
            logger.warning(f"Message too long ({len(message)} chars). Splitting...")
            chunks, current = [], ""
            title = f"Bias Scan Results ({len(bias_results)} tokens)"
            part_num = 1
            for line in message.split('\n'):
                if len(current) + len(line) + len(title) + 20 < max_len:
                    current += line + "\n"
                else:
                    chunks.append(current)
                    current = line + "\n"
                    part_num += 1
            chunks.append(current)

            for i, chunk in enumerate(chunks, 1):
                if chunk.strip():
                    await update.message.reply_text(
                        f"**{title} (Part {i}/{len(chunks)})**\n\n{chunk}",
                        parse_mode='Markdown'
                    )
                    await asyncio.sleep(0.6)

    except Exception as e:
        logger.error(f"Error in /bias: {e}")
        await update.message.reply_text("üö® Oops! Something went wrong with the /bias scan.")

"""### Analyze"""

async def detect_macd_divergences(symbol: str, timeframe: str, exchange) -> dict:
    """Detecta divergencias del MACD (implementaci√≥n del c√≥digo anterior)."""
    result = {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []}, 'error': None}

    try:
        ohlcv = await exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=200)
        await asyncio.sleep(API_CALL_PAUSE)

        if not ohlcv or len(ohlcv) < MACD_SETTINGS['slow'] + 5 + 50:
            return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                    'error': f'Datos OHLCV insuficientes para {symbol} en {timeframe}'}

        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)

        df.ta.macd(fast=MACD_SETTINGS['fast'], slow=MACD_SETTINGS['slow'], signal=MACD_SETTINGS['signal'], append=True)
        hist_col = f'MACDh_{MACD_SETTINGS["fast"]}_{MACD_SETTINGS["slow"]}_{MACD_SETTINGS["signal"]}'

        if hist_col not in df.columns or df[hist_col].dropna().empty:
            return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                    'error': f'C√°lculo del MACD fall√≥ para {symbol} en {timeframe}'}

        for candle_idx in range(6):  # √öltimas 6 velas
            if (candle_idx < len(df) - 1 and df[hist_col].iloc[-(candle_idx + 1)] < 0 and df[hist_col].iloc[-candle_idx] >= 0) or (candle_idx == 0):
                price_nearest = float('inf')
                macd_nearest = 0.0
                macd_nearest_idx = 0
                price_furthest = float('inf')
                macd_furthest = 0.0
                macd_furthest_idx = 0

                j = candle_idx + 1 if candle_idx > 0 else 0
                while j < len(df) and df[hist_col].iloc[-j] < 0:
                    price_nearest = min(df['low'].iloc[-j], price_nearest)
                    macd_nearest = min(df[hist_col].iloc[-j], macd_nearest)
                    if df[hist_col].iloc[-j] == macd_nearest:
                        macd_nearest_idx = j
                    j += 1
                while j < len(df) and df[hist_col].iloc[-j] >= 0:
                    j += 1
                while j < len(df) and df[hist_col].iloc[-j] < 0:
                    price_furthest = min(df['low'].iloc[-j], price_furthest)
                    macd_furthest = min(df[hist_col].iloc[-j], macd_furthest)
                    if df[hist_col].iloc[-j] == macd_furthest:
                        macd_furthest_idx = j
                    j += 1

                if price_nearest < price_furthest and macd_nearest > macd_furthest:
                    result['bullish']['classic'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': macd_nearest_idx,
                        'furthest_idx': macd_furthest_idx
                    })
                elif price_nearest > price_furthest and macd_nearest < macd_furthest:
                    result['bullish']['hidden'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': macd_nearest_idx,
                        'furthest_idx': macd_furthest_idx
                    })

            if (candle_idx < len(df) - 1 and df[hist_col].iloc[-(candle_idx + 1)] > 0 and df[hist_col].iloc[-candle_idx] <= 0) or (candle_idx == 0):
                price_nearest = 0.0
                macd_nearest = 0.0
                macd_nearest_idx = 0
                price_furthest = 0.0
                macd_furthest = 0.0
                macd_furthest_idx = 0

                j = candle_idx + 1 if candle_idx > 0 else 0
                while j < len(df) and df[hist_col].iloc[-j] > 0:
                    price_nearest = max(df['high'].iloc[-j], price_nearest)
                    macd_nearest = max(df[hist_col].iloc[-j], macd_nearest)
                    if df[hist_col].iloc[-j] == macd_nearest:
                        macd_nearest_idx = j
                    j += 1
                while j < len(df) and df[hist_col].iloc[-j] <= 0:
                    j += 1
                while j < len(df) and df[hist_col].iloc[-j] > 0:
                    price_furthest = max(df['high'].iloc[-j], price_furthest)
                    macd_furthest = max(df[hist_col].iloc[-j], macd_furthest)
                    if df[hist_col].iloc[-j] == macd_furthest:
                        macd_furthest_idx = j
                    j += 1

                if price_nearest > price_furthest and macd_nearest < macd_furthest:
                    result['bearish']['classic'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': macd_nearest_idx,
                        'furthest_idx': macd_furthest_idx
                    })
                elif price_nearest < price_furthest and macd_nearest > macd_furthest:
                    result['bearish']['hidden'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': macd_nearest_idx,
                        'furthest_idx': macd_furthest_idx
                    })

        return result

    except ccxt.BadSymbol:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'S√≠mbolo {symbol} no encontrado'}
    except ccxt.NetworkError as e:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error de red: {e}'}
    except ccxt.ExchangeError as e:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error del exchange: {e}'}
    except Exception as e:
        logger.warning(f"Error en detecci√≥n de divergencias para {symbol} en {timeframe}: {e}")
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error de c√°lculo: {e}'}

async def detect_rsi_divergences(symbol: str, timeframe: str, exchange) -> dict:
    """Detecta divergencias del RSI (implementaci√≥n del c√≥digo anterior)."""
    result = {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []}, 'error': None}

    try:
        ohlcv = await exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=200)
        await asyncio.sleep(API_CALL_PAUSE)

        if not ohlcv or len(ohlcv) < RSI_SETTINGS['length'] + 5 + 50:
            return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                    'error': f'Datos OHLCV insuficientes para {symbol} en {timeframe}'}

        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)

        df['rsi'] = df.ta.rsi(length=RSI_SETTINGS['length'])

        if 'rsi' not in df.columns or df['rsi'].dropna().empty:
            return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                    'error': f'C√°lculo del RSI fall√≥ para {symbol} en {timeframe}'}

        for candle_idx in range(6):
            if candle_idx < len(df) - 2:
                window = df.iloc[-(candle_idx + 3):-(candle_idx - 1) if candle_idx > 1 else None]
                if len(window) < 2:
                    continue

                price_nearest = window['low'].min()
                rsi_nearest = window['rsi'].min()
                price_nearest_idx = window['low'].idxmin()
                rsi_nearest_idx = window['rsi'].idxmin()
                nearest_idx = df.index.get_loc(price_nearest_idx)

                prev_window = df.iloc[-(candle_idx + 15):-(candle_idx + 3)]
                if len(prev_window) < 2:
                    continue

                price_furthest = prev_window['low'].min()
                rsi_furthest = prev_window['rsi'].min()
                price_furthest_idx = prev_window['low'].idxmin()
                rsi_furthest_idx = prev_window['rsi'].idxmin()
                furthest_idx = df.index.get_loc(price_furthest_idx)

                if price_nearest < price_furthest and rsi_nearest > rsi_furthest:
                    result['bullish']['classic'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': nearest_idx,
                        'furthest_idx': furthest_idx
                    })
                elif price_nearest > price_furthest and rsi_nearest < rsi_furthest:
                    result['bullish']['hidden'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': nearest_idx,
                        'furthest_idx': furthest_idx
                    })

                price_nearest = window['high'].max()
                rsi_nearest = window['rsi'].max()
                price_nearest_idx = window['high'].idxmax()
                rsi_nearest_idx = window['rsi'].idxmax()
                nearest_idx = df.index.get_loc(price_nearest_idx)

                price_furthest = prev_window['high'].max()
                rsi_furthest = prev_window['rsi'].max()
                price_furthest_idx = prev_window['high'].idxmax()
                rsi_furthest_idx = prev_window['rsi'].idxmax()
                furthest_idx = df.index.get_loc(price_furthest_idx)

                if price_nearest > price_furthest and rsi_nearest < rsi_furthest:
                    result['bearish']['classic'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': nearest_idx,
                        'furthest_idx': furthest_idx
                    })
                elif price_nearest < price_furthest and rsi_nearest > rsi_furthest:
                    result['bearish']['hidden'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': nearest_idx,
                        'furthest_idx': furthest_idx
                    })

        return result

    except ccxt.BadSymbol:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'S√≠mbolo {symbol} no encontrado'}
    except ccxt.NetworkError as e:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error de red: {e}'}
    except ccxt.ExchangeError as e:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error del exchange: {e}'}
    except Exception as e:
        logger.warning(f"Error en detecci√≥n de divergencias para {symbol} en {timeframe}: {e}")
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error de c√°lculo: {e}'}

# --- Comando /analyze Modificado ---
async def analyze_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """üîç /analyze [S√çMBOLO]: Analiza un s√≠mbolo para sesgo alcista/bajista con reglas personalizadas."""
    if not context.args:
        await update.message.reply_text(
            "üö® **Error**: Por favor proporciona un s√≠mbolo. Ejemplo: `/analyze BTC/USDT`",
            parse_mode='Markdown'
        )
        return

    symbol = context.args[0].upper()
    if symbol not in VALID_TOKENS:
        await update.message.reply_text(
            f"üö® **Error**: El s√≠mbolo ${symbol} no es v√°lido o no est√° soportado en {CCXT_EXCHANGE_ID}. " +
            f"Usa un s√≠mbolo de la lista de tokens soportados, como BTC/USDT.",
            parse_mode='Markdown'
        )
        return

    await update.message.reply_text(
        f"üîç **An√°lisis Iniciado para ${symbol}** en {', '.join(ANALYSIS_TIMEFRAMES)} v√≠a {CCXT_EXCHANGE_ID}.\n" +
        f"üìä Calculando sesgo alcista/bajista con divergencias, MACD, RSI, MAs, tendencia, volumen y velas.\n" +
        f"‚è≥ *Esto puede tomar un momento...*",
        parse_mode='Markdown'
    )

    try:
        # Analizar el s√≠mbolo objetivo
        target_scores = {}
        target_details = {}
        for tf in ANALYSIS_TIMEFRAMES:
            up_score, down_score, details = await calculate_tf_scores(symbol, tf, exchange)
            target_scores[tf] = (up_score, down_score)
            target_details[tf] = details

        # Analizar contexto BTC y ETH (si no es el s√≠mbolo objetivo)
        context_scores = {'BTC/USDT': {}, 'ETH/USDT': {}}
        for ctx_symbol in ['BTC/USDT', 'ETH/USDT']:
            if ctx_symbol != symbol:
                for tf in ANALYSIS_TIMEFRAMES:
                    up_score, down_score, _ = await calculate_tf_scores(ctx_symbol, tf, exchange)
                    context_scores[ctx_symbol][tf] = (up_score, down_score)

        # Calcular sesgo total
        total_up = sum(up for up, _ in target_scores.values())
        total_down = sum(down for _, down in target_scores.values())
        bias = "Alcista" if total_up > total_down else "Bajista" if total_down > total_up else "Neutral"

        # Construir respuesta
        parts = [f"üìä **An√°lisis de ${symbol} ({', '.join(ANALYSIS_TIMEFRAMES)})**"]
        parts.append(f"üîç **Sesgo General**: {bias} (Puntuaci√≥n Alcista: {total_up}, Bajista: {total_down})")

        # Detalles por temporalidad
        for tf in ANALYSIS_TIMEFRAMES:
            up, down = target_scores[tf]
            details = target_details[tf]
            parts.append(f"\nüìà **{tf}**: Alcista: {up}, Bajista: {down}")
            if details:
                parts.extend([f"‚Ä¢ {detail}" for detail in details])
            else:
                parts.append("‚Ä¢ Sin se√±ales significativas")

        # Contexto BTC/ETH
        parts.append("\nüåç **Contexto del Mercado (BTC/ETH)**")
        for ctx_symbol in ['BTC/USDT', 'ETH/USDT']:
            if ctx_symbol != symbol and ctx_symbol in context_scores:
                ctx_total_up = sum(up for up, _ in context_scores[ctx_symbol].values())
                ctx_total_down = sum(down for _, down in context_scores[ctx_symbol].values())
                ctx_bias = "Alcista" if ctx_total_up > ctx_total_down else "Bajista" if ctx_total_down > ctx_total_up else "Neutral"
                parts.append(f"‚Ä¢ ${ctx_symbol}: {ctx_bias} (Alcista: {ctx_total_up}, Bajista: {ctx_total_down})")

        parts.append("\n‚ö†Ô∏è *¬°Experimental, no es asesoramiento financiero! Haz tu propia investigaci√≥n.*")
        message = "\n".join(parts)

        # Manejar mensajes largos
        max_len = 4096
        if len(message) <= max_len:
            await update.message.reply_text(message, parse_mode='Markdown')
        else:
            logger.warning(f"Mensaje demasiado largo ({len(message)} caracteres). Dividiendo...")
            chunks, current = [], ""
            title = f"An√°lisis de ${symbol}"
            part_num = 1
            for line in message.split('\n'):
                if len(current) + len(line) + len(title) + 20 < max_len:
                    current += line + "\n"
                else:
                    chunks.append(current)
                    current = line + "\n"
                    part_num += 1
            chunks.append(current)

            for i, chunk in enumerate(chunks, 1):
                if chunk.strip():
                    await update.message.reply_text(
                        f"**{title} (Parte {i}/{len(chunks)})**\n\n{chunk}",
                        parse_mode='Markdown'
                    )
                    await asyncio.sleep(0.6)

    except Exception as e:
        logger.error(f"Error en /analyze para {symbol}: {e}")
        await update.message.reply_text(
            f"üö® ¬°Ups! Algo sali√≥ mal al analizar ${symbol}.",
            parse_mode='Markdown'
        )

"""### MACD DIV"""

# New configuration for /macd_divergences
MACD_DIVERGENCE_TIMEFRAMES = ['5m', '15m', '30m', '1h', '4h']
MACD_LOOKBACK_CANDLES = 5  # Check current candle + 5 previous
MACD_SETTINGS = {'fast': 12, 'slow': 26, 'signal': 9}  # Same as Pine Script

# New /macd_divergences command
async def macd_divergences_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """üéØ /macd_divergences: Detecta divergencias del MACD en las √∫ltimas 6 velas para tokens."""
    if not VALID_TOKENS:
        await update.message.reply_text(
            f"üö® **Error**: No hay pares de trading v√°lidos disponibles en {CCXT_EXCHANGE_ID}. Revisa los logs."
        )
        return

    await update.message.reply_text(
        f"üîç **Escaneo de Divergencias MACD Iniciado!** Analizando {len(VALID_TOKENS)}/{len(TOKENS_TO_ANALYZE)} tokens v√°lidos en {', '.join(MACD_DIVERGENCE_TIMEFRAMES)}.\n"
        f"üìä Buscando divergencias alcistas/bajistas (cl√°sicas/ocultas) en las √∫ltimas 6 velas v√≠a {CCXT_EXCHANGE_ID}.\n"
        f"‚è≥ *¬°Esto puede tomar unos minutos...*"
    )

    try:
        # Almacenar resultados
        divergences = {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []}}
        errors = []

        # Procesar cada token v√°lido
        for i, symbol in enumerate(VALID_TOKENS, 1):
            logger.info(f"Procesando {symbol} ({i}/{len(VALID_TOKENS)})")
            for tf in MACD_DIVERGENCE_TIMEFRAMES:
                result = await detect_macd_divergences(symbol, tf, exchange)

                if result['error']:
                    errors.append(f"{symbol}@{tf}: {result['error'][:50]}...")

                # Recopilar divergencias
                for div_type in ['classic', 'hidden']:
                    for entry in result['bullish'][div_type]:
                        divergences['bullish'][div_type].append({
                            'symbol': symbol,
                            'timeframe': tf,
                            'candle_idx': entry['candle_idx']
                        })
                    for entry in result['bearish'][div_type]:
                        divergences['bearish'][div_type].append({
                            'symbol': symbol,
                            'timeframe': tf,
                            'candle_idx': entry['candle_idx']
                        })

            # Reportar progreso cada 10 tokens
            if i % 10 == 0:
                await update.message.reply_text(
                    f"‚è±Ô∏è Progreso: {i}/{len(VALID_TOKENS)} tokens escaneados."
                )
            await asyncio.sleep(API_CALL_PAUSE)

        # Construir respuesta
        parts = [f"üìä **Resultados del Escaneo de Divergencias MACD ({len(VALID_TOKENS)}/{len(TOKENS_TO_ANALYZE)} tokens analizados)**"]

        # Divergencias Alcistas Cl√°sicas
        if divergences['bullish']['classic']:
            parts.append("\nüìà **Divergencias Alcistas Cl√°sicas**")
            for div in sorted(divergences['bullish']['classic'], key=lambda x: (x['symbol'], x['timeframe'])):
                parts.append(f"‚Ä¢ ${div['symbol']} en {div['timeframe']}: Vela {div['candle_idx'] + 1} atr√°s")
        else:
            parts.append("\nüìà **Divergencias Alcistas Cl√°sicas**: Ninguna encontrada.")

        # Divergencias Alcistas Ocultas
        if divergences['bullish']['hidden']:
            parts.append("\nüìà **Divergencias Alcistas Ocultas**")
            for div in sorted(divergences['bullish']['hidden'], key=lambda x: (x['symbol'], x['timeframe'])):
                parts.append(f"‚Ä¢ ${div['symbol']} en {div['timeframe']}: Vela {div['candle_idx'] + 1} atr√°s")
        else:
            parts.append("\nüìà **Divergencias Alcistas Ocultas**: Ninguna encontrada.")

        # Divergencias Bajistas Cl√°sicas
        if divergences['bearish']['classic']:
            parts.append("\nüìâ **Divergencias Bajistas Cl√°sicas**")
            for div in sorted(divergences['bearish']['classic'], key=lambda x: (x['symbol'], x['timeframe'])):
                parts.append(f"‚Ä¢ ${div['symbol']} en {div['timeframe']}: Vela {div['candle_idx'] + 1} atr√°s")
        else:
            parts.append("\nüìâ **Divergencias Bajistas Cl√°sicas**: Ninguna encontrada.")

        # Divergencias Bajistas Ocultas
        if divergences['bearish']['hidden']:
            parts.append("\nüìâ **Divergencias Bajistas Ocultas**")
            for div in sorted(divergences['bearish']['hidden'], key=lambda x: (x['symbol'], x['timeframe'])):
                parts.append(f"‚Ä¢ ${div['symbol']} en {div['timeframe']}: Vela {div['candle_idx'] + 1} atr√°s")
        else:
            parts.append("\nüìâ **Divergencias Bajistas Ocultas**: Ninguna encontrada.")

        # Tokens No Soportados
        invalid_tokens = set(TOKENS_TO_ANALYZE) - set(VALID_TOKENS)
        if invalid_tokens:
            parts.append("\n‚ö†Ô∏è **Tokens No Soportados (No en el Exchange)**")
            parts.extend([f"‚Ä¢ {token}" for token in sorted(invalid_tokens)[:5]])
            if len(invalid_tokens) > 5:
                parts.append(f"‚Ä¢ ...y {len(invalid_tokens) - 5} m√°s.")

        # Errores
        if errors:
            parts.append("\n‚ö†Ô∏è **Problemas de Procesamiento**")
            parts.extend([f"‚Ä¢ {err}" for err in errors[:5]])
            if len(errors) > 5:
                parts.append(f"‚Ä¢ ...y {len(errors) - 5} m√°s.")

        parts.append("\n‚ÑπÔ∏è *¬°No es asesoramiento financiero! Los resultados son solo para informaci√≥n. Haz tu propia investigaci√≥n.*")
        message = "\n".join(parts)

        # Manejar mensajes largos
        max_len = 4096
        if len(message) <= max_len:
            await update.message.reply_text(message, parse_mode='Markdown')
        else:
            logger.warning(f"Mensaje demasiado largo ({len(message)} caracteres). Dividiendo...")
            chunks, current = [], ""
            title = f"Resultados de Divergencias MACD ({len(VALID_TOKENS)} tokens)"
            part_num = 1
            for line in message.split('\n'):
                if len(current) + len(line) + len(title) + 20 < max_len:
                    current += line + "\n"
                else:
                    chunks.append(current)
                    current = line + "\n"
                    part_num += 1
            chunks.append(current)

            for i, chunk in enumerate(chunks, 1):
                if chunk.strip():
                    await update.message.reply_text(
                        f"**{title} (Parte {i}/{len(chunks)})**\n\n{chunk}",
                        parse_mode='Markdown'
                    )
                    await asyncio.sleep(0.6)

    except Exception as e:
        logger.error(f"Error en /macd_divergences: {e}")
        await update.message.reply_text("üö® ¬°Ups! Algo sali√≥ mal con el escaneo de /macd_divergences.")
# New function to detect MACD divergences
# --- Funci√≥n Corregida para Detectar Divergencias ---
async def detect_macd_divergences(symbol: str, timeframe: str, exchange) -> dict:
    """
    Detecta divergencias alcistas y bajistas del MACD (cl√°sicas y ocultas) en la vela actual o las √∫ltimas 5 velas.
    Devuelve: {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []}, 'error': str o None}
    Cada entrada: {'candle_idx': int (0-5, 0 es actual), 'nearest_idx': int, 'furthest_idx': int}
    """
    result = {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []}, 'error': None}

    try:
        # Obtener datos OHLCV
        ohlcv = await exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=200)
        await asyncio.sleep(API_CALL_PAUSE)

        if not ohlcv or len(ohlcv) < MACD_SETTINGS['slow'] + MACD_LOOKBACK_CANDLES + 50:
            return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                    'error': f'Datos OHLCV insuficientes para {symbol} en {timeframe}'}

        # Crear DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)

        # Calcular MACD
        df.ta.macd(fast=MACD_SETTINGS['fast'], slow=MACD_SETTINGS['slow'], signal=MACD_SETTINGS['signal'], append=True)
        hist_col = f'MACDh_{MACD_SETTINGS["fast"]}_{MACD_SETTINGS["slow"]}_{MACD_SETTINGS["signal"]}'

        if hist_col not in df.columns or df[hist_col].dropna().empty:
            return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                    'error': f'C√°lculo del MACD fall√≥ para {symbol} en {timeframe}'}

        # Comprobar divergencias en las √∫ltimas 6 velas (√≠ndices 0 a 5, 0 es la vela actual)
        for candle_idx in range(MACD_LOOKBACK_CANDLES + 1):  # 0 (actual) a 5 (5 velas atr√°s)
            # Comprobar Divergencia Alcista
            if (candle_idx < len(df) - 1 and df[hist_col].iloc[-(candle_idx + 1)] < 0 and df[hist_col].iloc[-candle_idx] >= 0) or (candle_idx == 0):
                price_nearest = float('inf')
                macd_nearest = 0.0
                macd_nearest_idx = 0
                price_furthest = float('inf')
                macd_furthest = 0.0
                macd_furthest_idx = 0

                j = candle_idx + 1 if candle_idx > 0 else 0
                # Encontrar regi√≥n negativa m√°s cercana
                while j < len(df) and df[hist_col].iloc[-j] < 0:
                    price_nearest = min(df['low'].iloc[-j], price_nearest)
                    macd_nearest = min(df[hist_col].iloc[-j], macd_nearest)
                    if df[hist_col].iloc[-j] == macd_nearest:
                        macd_nearest_idx = j
                    j += 1
                # Saltar regi√≥n positiva
                while j < len(df) and df[hist_col].iloc[-j] >= 0:
                    j += 1
                # Encontrar regi√≥n negativa m√°s lejana
                while j < len(df) and df[hist_col].iloc[-j] < 0:
                    price_furthest = min(df['low'].iloc[-j], price_furthest)
                    macd_furthest = min(df[hist_col].iloc[-j], macd_furthest)
                    if df[hist_col].iloc[-j] == macd_furthest:
                        macd_furthest_idx = j
                    j += 1

                # Verificar divergencia
                if price_nearest < price_furthest and macd_nearest > macd_furthest:
                    result['bullish']['classic'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': macd_nearest_idx,
                        'furthest_idx': macd_furthest_idx
                    })
                elif price_nearest > price_furthest and macd_nearest < macd_furthest:
                    result['bullish']['hidden'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': macd_nearest_idx,
                        'furthest_idx': macd_furthest_idx
                    })

            # Comprobar Divergencia Bajista
            if (candle_idx < len(df) - 1 and df[hist_col].iloc[-(candle_idx + 1)] > 0 and df[hist_col].iloc[-candle_idx] <= 0) or (candle_idx == 0):
                price_nearest = 0.0
                macd_nearest = 0.0
                macd_nearest_idx = 0
                price_furthest = 0.0
                macd_furthest = 0.0
                macd_furthest_idx = 0

                j = candle_idx + 1 if candle_idx > 0 else 0
                # Encontrar regi√≥n positiva m√°s cercana
                while j < len(df) and df[hist_col].iloc[-j] > 0:
                    price_nearest = max(df['high'].iloc[-j], price_nearest)
                    macd_nearest = max(df[hist_col].iloc[-j], macd_nearest)
                    if df[hist_col].iloc[-j] == macd_nearest:
                        macd_nearest_idx = j
                    j += 1
                # Saltar regi√≥n negativa
                while j < len(df) and df[hist_col].iloc[-j] <= 0:
                    j += 1
                # Encontrar regi√≥n positiva m√°s lejana
                while j < len(df) and df[hist_col].iloc[-j] > 0:
                    price_furthest = max(df['high'].iloc[-j], price_furthest)
                    macd_furthest = max(df[hist_col].iloc[-j], macd_furthest)
                    if df[hist_col].iloc[-j] == macd_furthest:
                        macd_furthest_idx = j
                    j += 1

                # Verificar divergencia
                if price_nearest > price_furthest and macd_nearest < macd_furthest:
                    result['bearish']['classic'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': macd_nearest_idx,
                        'furthest_idx': macd_furthest_idx
                    })
                elif price_nearest < price_furthest and macd_nearest > macd_furthest:
                    result['bearish']['hidden'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': macd_nearest_idx,
                        'furthest_idx': macd_furthest_idx
                    })

        return result

    except ccxt.BadSymbol:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'S√≠mbolo {symbol} no encontrado'}
    except ccxt.NetworkError as e:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error de red: {e}'}
    except ccxt.ExchangeError as e:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error del exchange: {e}'}
    except Exception as e:
        logger.warning(f"Error en detecci√≥n de divergencias para {symbol} en {timeframe}: {e}")
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error de c√°lculo: {e}'}

"""### RSI DIV"""

RSI_DIVERGENCE_TIMEFRAMES = ['5m', '15m', '30m', '1h', '4h']
RSI_LOOKBACK_CANDLES = 5  # Comprobar vela actual + 5 anteriores
RSI_SETTINGS = {'length': 14}  # RSI est√°ndar de 14 per√≠odos

# --- Nueva Funci√≥n para Detectar Divergencias del RSI ---
async def detect_rsi_divergences(symbol: str, timeframe: str, exchange) -> dict:
    """
    Detecta divergencias alcistas y bajistas del RSI (cl√°sicas y ocultas) en la vela actual o las √∫ltimas 5 velas.
    Devuelve: {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []}, 'error': str o None}
    Cada entrada: {'candle_idx': int (0-5, 0 es actual), 'nearest_idx': int, 'furthest_idx': int}
    """
    result = {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []}, 'error': None}

    try:
        # Obtener datos OHLCV
        ohlcv = await exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=200)
        await asyncio.sleep(API_CALL_PAUSE)

        if not ohlcv or len(ohlcv) < RSI_SETTINGS['length'] + RSI_LOOKBACK_CANDLES + 50:
            return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                    'error': f'Datos OHLCV insuficientes para {symbol} en {timeframe}'}

        # Crear DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)

        # Calcular RSI
        df['rsi'] = df.ta.rsi(length=RSI_SETTINGS['length'])

        if 'rsi' not in df.columns or df['rsi'].dropna().empty:
            return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                    'error': f'C√°lculo del RSI fall√≥ para {symbol} en {timeframe}'}

        # Comprobar divergencias en las √∫ltimas 6 velas (√≠ndices 0 a 5, 0 es la vela actual)
        for candle_idx in range(RSI_LOOKBACK_CANDLES + 1):  # 0 (actual) a 5 (5 velas atr√°s)
            # Comprobar Divergencia Alcista (buscar m√≠nimos)
            if candle_idx < len(df) - 2:  # Necesitamos al menos 2 velas para comparar
                # Encontrar m√≠nimos en precio y RSI en una ventana alrededor de la vela
                window = df.iloc[-(candle_idx + 3):-(candle_idx - 1) if candle_idx > 1 else None]
                if len(window) < 2:
                    continue

                # M√≠nimo reciente
                price_nearest = window['low'].min()
                rsi_nearest = window['rsi'].min()
                price_nearest_idx = window['low'].idxmin()
                rsi_nearest_idx = window['rsi'].idxmin()
                nearest_idx = df.index.get_loc(price_nearest_idx)

                # M√≠nimo anterior (ventana m√°s antigua)
                prev_window = df.iloc[-(candle_idx + 15):-(candle_idx + 3)]
                if len(prev_window) < 2:
                    continue

                price_furthest = prev_window['low'].min()
                rsi_furthest = prev_window['rsi'].min()
                price_furthest_idx = prev_window['low'].idxmin()
                rsi_furthest_idx = prev_window['rsi'].idxmin()
                furthest_idx = df.index.get_loc(price_furthest_idx)

                # Verificar divergencia alcista
                if price_nearest < price_furthest and rsi_nearest > rsi_furthest:
                    result['bullish']['classic'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': nearest_idx,
                        'furthest_idx': furthest_idx
                    })
                elif price_nearest > price_furthest and rsi_nearest < rsi_furthest:
                    result['bullish']['hidden'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': nearest_idx,
                        'furthest_idx': furthest_idx
                    })

            # Comprobar Divergencia Bajista (buscar m√°ximos)
            if candle_idx < len(df) - 2:
                # M√°ximo reciente
                price_nearest = window['high'].max()
                rsi_nearest = window['rsi'].max()
                price_nearest_idx = window['high'].idxmax()
                rsi_nearest_idx = window['rsi'].idxmax()
                nearest_idx = df.index.get_loc(price_nearest_idx)

                # M√°ximo anterior
                price_furthest = prev_window['high'].max()
                rsi_furthest = prev_window['rsi'].max()
                price_furthest_idx = prev_window['high'].idxmax()
                rsi_furthest_idx = prev_window['rsi'].idxmax()
                furthest_idx = df.index.get_loc(price_furthest_idx)

                # Verificar divergencia bajista
                if price_nearest > price_furthest and rsi_nearest < rsi_furthest:
                    result['bearish']['classic'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': nearest_idx,
                        'furthest_idx': furthest_idx
                    })
                elif price_nearest < price_furthest and rsi_nearest > rsi_furthest:
                    result['bearish']['hidden'].append({
                        'candle_idx': candle_idx,
                        'nearest_idx': nearest_idx,
                        'furthest_idx': furthest_idx
                    })

        return result

    except ccxt.BadSymbol:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'S√≠mbolo {symbol} no encontrado'}
    except ccxt.NetworkError as e:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error de red: {e}'}
    except ccxt.ExchangeError as e:
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error del exchange: {e}'}
    except Exception as e:
        logger.warning(f"Error en detecci√≥n de divergencias para {symbol} en {timeframe}: {e}")
        return {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []},
                'error': f'Error de c√°lculo: {e}'}

# --- Nuevo Comando /rsi_divergences ---
async def rsi_divergences_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """üéØ /rsi_divergences: Detecta divergencias del RSI en las √∫ltimas 6 velas para tokens."""
    if not VALID_TOKENS:
        await update.message.reply_text(
            f"üö® **Error**: No hay pares de trading v√°lidos disponibles en {CCXT_EXCHANGE_ID}. Revisa los logs."
        )
        return

    await update.message.reply_text(
        f"üîç **Escaneo de Divergencias RSI Iniciado!** Analizando {len(VALID_TOKENS)}/{len(TOKENS_TO_ANALYZE)} tokens v√°lidos en {', '.join(RSI_DIVERGENCE_TIMEFRAMES)}.\n"
        f"üìä Buscando divergencias alcistas/bajistas (cl√°sicas/ocultas) en las √∫ltimas 6 velas v√≠a {CCXT_EXCHANGE_ID}.\n"
        f"‚è≥ *¬°Esto puede tomar unos minutos...*"
    )

    try:
        # Almacenar resultados
        divergences = {'bullish': {'classic': [], 'hidden': []}, 'bearish': {'classic': [], 'hidden': []}}
        errors = []

        # Procesar cada token v√°lido
        for i, symbol in enumerate(VALID_TOKENS, 1):
            logger.info(f"Procesando {symbol} ({i}/{len(VALID_TOKENS)})")
            for tf in RSI_DIVERGENCE_TIMEFRAMES:
                result = await detect_rsi_divergences(symbol, tf, exchange)

                if result['error']:
                    errors.append(f"{symbol}@{tf}: {result['error'][:50]}...")

                # Recopilar divergencias
                for div_type in ['classic', 'hidden']:
                    for entry in result['bullish'][div_type]:
                        divergences['bullish'][div_type].append({
                            'symbol': symbol,
                            'timeframe': tf,
                            'candle_idx': entry['candle_idx']
                        })
                    for entry in result['bearish'][div_type]:
                        divergences['bearish'][div_type].append({
                            'symbol': symbol,
                            'timeframe': tf,
                            'candle_idx': entry['candle_idx']
                        })

            # Reportar progreso cada 10 tokens
            if i % 10 == 0:
                await update.message.reply_text(
                    f"‚è±Ô∏è Progreso: {i}/{len(VALID_TOKENS)} tokens escaneados."
                )
            await asyncio.sleep(API_CALL_PAUSE)

        # Construir respuesta
        parts = [f"üìä **Resultados del Escaneo de Divergencias RSI ({len(VALID_TOKENS)}/{len(TOKENS_TO_ANALYZE)} tokens analizados)**"]

        # Divergencias Alcistas Cl√°sicas
        if divergences['bullish']['classic']:
            parts.append("\nüìà **Divergencias Alcistas Cl√°sicas**")
            for div in sorted(divergences['bullish']['classic'], key=lambda x: (x['symbol'], x['timeframe'])):
                parts.append(f"‚Ä¢ ${div['symbol']} en {div['timeframe']}: Vela {div['candle_idx'] + 1} atr√°s")
        else:
            parts.append("\nüìà **Divergencias Alcistas Cl√°sicas**: Ninguna encontrada.")

        # Divergencias Alcistas Ocultas
        if divergences['bullish']['hidden']:
            parts.append("\nüìà **Divergencias Alcistas Ocultas**")
            for div in sorted(divergences['bullish']['hidden'], key=lambda x: (x['symbol'], x['timeframe'])):
                parts.append(f"‚Ä¢ ${div['symbol']} en {div['timeframe']}: Vela {div['candle_idx'] + 1} atr√°s")
        else:
            parts.append("\nüìà **Divergencias Alcistas Ocultas**: Ninguna encontrada.")

        # Divergencias Bajistas Cl√°sicas
        if divergences['bearish']['classic']:
            parts.append("\nüìâ **Divergencias Bajistas Cl√°sicas**")
            for div in sorted(divergences['bearish']['classic'], key=lambda x: (x['symbol'], x['timeframe'])):
                parts.append(f"‚Ä¢ ${div['symbol']} en {div['timeframe']}: Vela {div['candle_idx'] + 1} atr√°s")
        else:
            parts.append("\nüìâ **Divergencias Bajistas Cl√°sicas**: Ninguna encontrada.")

        # Divergencias Bajistas Ocultas
        if divergences['bearish']['hidden']:
            parts.append("\nüìâ **Divergencias Bajistas Ocultas**")
            for div in sorted(divergences['bearish']['hidden'], key=lambda x: (x['symbol'], x['timeframe'])):
                parts.append(f"‚Ä¢ ${div['symbol']} en {div['timeframe']}: Vela {div['candle_idx'] + 1} atr√°s")
        else:
            parts.append("\nüìâ **Divergencias Bajistas Ocultas**: Ninguna encontrada.")

        # Tokens No Soportados
        invalid_tokens = set(TOKENS_TO_ANALYZE) - set(VALID_TOKENS)
        if invalid_tokens:
            parts.append("\n‚ö†Ô∏è **Tokens No Soportados (No en el Exchange)**")
            parts.extend([f"‚Ä¢ {token}" for token in sorted(invalid_tokens)[:5]])
            if len(invalid_tokens) > 5:
                parts.append(f"‚Ä¢ ...y {len(invalid_tokens) - 5} m√°s.")

        # Errores
        if errors:
            parts.append("\n‚ö†Ô∏è **Problemas de Procesamiento**")
            parts.extend([f"‚Ä¢ {err}" for err in errors[:5]])
            if len(errors) > 5:
                parts.append(f"‚Ä¢ ...y {len(errors) - 5} m√°s.")

        parts.append("\n‚ÑπÔ∏è *¬°No es asesoramiento financiero! Los resultados son solo para informaci√≥n. Haz tu propia investigaci√≥n.*")
        message = "\n".join(parts)

        # Manejar mensajes largos
        max_len = 4096
        if len(message) <= max_len:
            await update.message.reply_text(message, parse_mode='Markdown')
        else:
            logger.warning(f"Mensaje demasiado largo ({len(message)} caracteres). Dividiendo...")
            chunks, current = [], ""
            title = f"Resultados de Divergencias RSI ({len(VALID_TOKENS)} tokens)"
            part_num = 1
            for line in message.split('\n'):
                if len(current) + len(line) + len(title) + 20 < max_len:
                    current += line + "\n"
                else:
                    chunks.append(current)
                    current = line + "\n"
                    part_num += 1
            chunks.append(current)

            for i, chunk in enumerate(chunks, 1):
                if chunk.strip():
                    await update.message.reply_text(
                        f"**{title} (Parte {i}/{len(chunks)})**\n\n{chunk}",
                        parse_mode='Markdown'
                    )
                    await asyncio.sleep(0.6)

    except Exception as e:
        logger.error(f"Error en /rsi_divergences: {e}")
        await update.message.reply_text("üö® ¬°Ups! Algo sali√≥ mal con el escaneo de /rsi_divergences.")

"""### CLEAN"""

# --- Cleanup Function & Main Execution ---

async def post_shutdown_cleanup(application: Application) -> None:
    """Closes the exchange connection when the bot stops."""
    if exchange and hasattr(exchange, 'close') and callable(exchange.close):
        logger.info("Closing the exchange connection...")
        try:
            await exchange.close()
            logger.info("Exchange connection closed successfully.")
        except Exception as e:
            logger.error(f"Error closing the exchange connection: {e}")

"""### MAIN"""

def main() -> None:
    """Inicia el bot."""
    # --- Pre-checks ---
    if not TELEGRAM_BOT_TOKEN or "TU_TOKEN_DE_TELEGRAM_AQUI" in TELEGRAM_BOT_TOKEN:
        print("\n" + "="*40)
        print("  ERROR: ¬°TOKEN DE TELEGRAM NO CONFIGURADO!")
        print("  Reemplaza 'TU_TOKEN_DE_TELEGRAM_AQUI_REEMPLAZAR' en el script.")
        print("="*40 + "\n")
        return

    if not exchange:
        print("\nERROR: No se pudo inicializar el exchange. Revisa los logs. Saliendo.\n")
        return

    # Validate tokens at startup
    async def initialize_valid_tokens():
        global VALID_TOKENS
        VALID_TOKENS = await get_valid_trading_pairs(exchange, TOKENS_TO_ANALYZE)
        if not VALID_TOKENS:
            logger.error("No se encontraron pares de trading v√°lidos. El bot puede no funcionar correctamente.")

    # Run async initialization
    loop = asyncio.get_event_loop()
    loop.run_until_complete(initialize_valid_tokens())

    # --- End Pre-checks ---

    # Build the application
    application = (
        ApplicationBuilder()
        .token(TELEGRAM_BOT_TOKEN)
        .post_shutdown(post_shutdown_cleanup)
        .build()
    )

    # Register command handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("rsi", rsi_command))
    application.add_handler(CommandHandler("analyze", analyze_command))
    application.add_handler(CommandHandler("bias", bias_command))
    application.add_handler(CommandHandler("macd_divergences", macd_divergences_command))  # New command
    application.add_handler(CommandHandler("rsi_divergences", rsi_divergences_command))  # Nuevo comando

    logger.info(f"Iniciando bot. Exchange: {CCXT_EXCHANGE_ID}. Moneda base: {QUOTE_CURRENCY}.")
    logger.info(f"/rsi comprobar√° ~{NUM_COINS_TO_PROCESS} monedas en {len(TIMEFRAMES_TO_CHECK)} temporalidades.")
    logger.info(f"/analyze comprobar√° {len(ANALYSIS_TIMEFRAMES)} temporalidades para Target/BTC/ETH.")
    logger.info(f"/bias comprobar√° {len(VALID_TOKENS)}/{len(TOKENS_TO_ANALYZE)} tokens v√°lidos en {len(ANALYSIS_TIMEFRAMES)} temporalidades.")
    logger.info(f"/macd_divergences comprobar√° {len(VALID_TOKENS)}/{len(TOKENS_TO_ANALYZE)} tokens v√°lidos en {len(MACD_DIVERGENCE_TIMEFRAMES)} temporalidades.")

    # Run the bot until the user presses Ctrl-C
    application.run_polling()


if __name__ == "__main__":
    main()